<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    

    <title>
      机器学习(coursera 斯坦福)第四周编程作业 | Sail 
    </title>

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    
      <meta name="author" content="Sail">


    
    

<div id="site_search">
            <input type="text" id="local-search-input" name="q" results="0" placeholder="search my blog..." class="form-control">
            <div id="local-search-result"></div>
    </div>
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-1345496474366685",
        enable_page_level_ads: true
      });
    </script>


    <meta name="description" content="Preface 本文是机器学习第四周的编程作业答案,完整题目以及代码见github   lrCostFunction.m  123456789101112131415161718192021222324252627282930313233343536373839404142434445464748function [J, grad] = lrCostFunction(theta, X, y, l">
<meta name="keywords" content="Neural Networks">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习(coursera 斯坦福)第四周编程作业 | Sail">
<meta property="og:url" content="http://www.sail.name/2018/06/03/the-fourth-week-homework-of-ML-Stanford/index.html">
<meta property="og:site_name" content="Sail">
<meta property="og:description" content="Preface 本文是机器学习第四周的编程作业答案,完整题目以及代码见github   lrCostFunction.m  123456789101112131415161718192021222324252627282930313233343536373839404142434445464748function [J, grad] = lrCostFunction(theta, X, y, l">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://www.sail.name/img/机器学习/the-fourth-week-homework-of-ML-Stanford/1.png">
<meta property="og:updated_time" content="2018-12-09T10:19:58.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习(coursera 斯坦福)第四周编程作业 | Sail">
<meta name="twitter:description" content="Preface 本文是机器学习第四周的编程作业答案,完整题目以及代码见github   lrCostFunction.m  123456789101112131415161718192021222324252627282930313233343536373839404142434445464748function [J, grad] = lrCostFunction(theta, X, y, l">
<meta name="twitter:image" content="http://www.sail.name/img/机器学习/the-fourth-week-homework-of-ML-Stanford/1.png">
    
    
    
      <link rel="icon" type="image/x-icon" href="/favicon.png">
    
    <link rel="stylesheet" href="/css/uno.css">
    <link rel="stylesheet" href="/css/highlight.css">
    <link rel="stylesheet" href="/css/archive.css">
    <link rel="stylesheet" href="/css/china-social-icon.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
<body>

    <!-- hexo-inject:begin --><!-- hexo-inject:end --><span class="mobile btn-mobile-menu">
        <i class="icon icon-list btn-mobile-menu__icon"></i>
        <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>

    </span>

    

<header class="panel-cover panel-cover--collapsed">


  <div class="panel-main">

  
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        

        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage">Sail</a></h1>
        <hr class="panel-cover__divider">

        
        <p class="panel-cover__description">
          手在键盘敲很轻
        </p>
        <hr class="panel-cover__divider panel-cover__divider--secondary">
        

        <div class="navigation-wrapper">

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">

              
                
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">首页</a></li>

              
                
                <li class="navigation__item"><a href="/about" title="" class="">关于</a></li>

              
                
                <li class="navigation__item"><a href="/archive" title="" class="">归档</a></li>

              
               <li class="navigation__item">
                    <a href="http://www.sail.name/Resource/" title="个人资源分享">Resource</a></li>

            </ul>
          </nav>
          <!-- ----------------------------
To add a new social icon simply duplicate one of the list items from below
and change the class in the <i> tag to match the desired social network
and then add your link to the <a>. Here is a full list of social network
classes that you can use:

    icon-social-500px
    icon-social-behance
    icon-social-delicious
    icon-social-designer-news
    icon-social-deviant-art
    icon-social-digg
    icon-social-dribbble
    icon-social-facebook
    icon-social-flickr
    icon-social-forrst
    icon-social-foursquare
    icon-social-github
    icon-social-google-plus
    icon-social-hi5
    icon-social-instagram
    icon-social-lastfm
    icon-social-linkedin
    icon-social-medium
    icon-social-myspace
    icon-social-path
    icon-social-pinterest
    icon-social-rdio
    icon-social-reddit
    icon-social-skype
    icon-social-spotify
    icon-social-stack-overflow
    icon-social-steam
    icon-social-stumbleupon
    icon-social-treehouse
    icon-social-tumblr
    icon-social-twitter
    icon-social-vimeo
    icon-social-xbox
    icon-social-yelp
    icon-social-youtube
    icon-social-zerply
    icon-mail

-------------------------------->

<!-- add social info here -->



<nav class="cover-navigation navigation--social">
  <ul class="navigation">
    
      <!-- Github -->
      <li class="navigation__item">
        <a href="https://github.com/iamsail" title="Huno on GitHub">
          <i class="icon icon-social-github"></i>
          <span class="label">GitHub</span>
        </a>
      </li>
    

    <!-- China social icon -->
    <!--
    
      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-douban'></i>
          <span class="label">Douban</span>
        </a>
      </li>

      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-weibo'></i>
          <span class="label">Weibo</span>
        </a>
      </li>

    -->



  </ul>
</nav>


        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner entry">
            

<article class="post-container post-container--single">

  <header class="post-header">
    
    <h1 class="post-title">机器学习(coursera 斯坦福)第四周编程作业</h1>

    

    <div class="post-meta">
      <time datetime="2018-06-03" class="post-meta__date date">2018-06-03</time> 

      <span class="post-meta__tags tags">

          
            <font class="categories">
            &#8226; 分类:
            <a class="categories-link" href="/categories/机器学习/">机器学习</a>
            </font>
          

          
             &#8226; 标签:
            <font class="tags">
              <a class="tags-link" href="/tags/Neural-Networks/">Neural Networks</a>
            </font>
          

      </span>
    </div>
    
    

  </header>

  <section id="post-content" class="article-content post">
    <h3 id="Preface"><a href="#Preface" class="headerlink" title=" Preface "></a><strong> Preface </strong></h3><p>本文是机器学习第四周的编程作业答案,完整题目以及代码见<a href="https://github.com/iamsail/ML-Stanford/tree/master/homework/fourth-week" target="_blank" rel="noopener">github</a></p>
<hr>
<h3 id="lrCostFunction-m"><a href="#lrCostFunction-m" class="headerlink" title=" lrCostFunction.m "></a><strong> lrCostFunction.m </strong></h3><p><img src="/img/机器学习/the-fourth-week-homework-of-ML-Stanford/1.png" alt="1.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">function [J, grad] = lrCostFunction(theta, X, y, lambda)</span><br><span class="line">%LRCOSTFUNCTION Compute cost and gradient for logistic regression with </span><br><span class="line">%regularization</span><br><span class="line">%   J = LRCOSTFUNCTION(theta, X, y, lambda) computes the cost of using</span><br><span class="line">%   theta as the parameter for regularized logistic regression and the</span><br><span class="line">%   gradient of the cost w.r.t. to the parameters. </span><br><span class="line"></span><br><span class="line">% Initialize some useful values</span><br><span class="line">m = length(y); % number of training examples</span><br><span class="line"></span><br><span class="line">% You need to return the following variables correctly </span><br><span class="line">J = 0;</span><br><span class="line">grad = zeros(size(theta));</span><br><span class="line"></span><br><span class="line">% ====================== YOUR CODE HERE ======================</span><br><span class="line">% Instructions: Compute the cost of a particular choice of theta.</span><br><span class="line">%               You should set J to the cost.</span><br><span class="line">%               Compute the partial derivatives and set grad to the partial</span><br><span class="line">%               derivatives of the cost w.r.t. each parameter in theta</span><br><span class="line">%</span><br><span class="line">% Hint: The computation of the cost function and gradients can be</span><br><span class="line">%       efficiently vectorized. For example, consider the computation</span><br><span class="line">%</span><br><span class="line">%           sigmoid(X * theta)</span><br><span class="line">%</span><br><span class="line">%       Each row of the resulting matrix will contain the value of the</span><br><span class="line">%       prediction for that example. You can make use of this to vectorize</span><br><span class="line">%       the cost function and gradient computations. </span><br><span class="line">%</span><br><span class="line">% Hint: When computing the gradient of the regularized cost function, </span><br><span class="line">%       there&apos;re many possible vectorized solutions, but one solution</span><br><span class="line">%       looks like:</span><br><span class="line">%           grad = (unregularized gradient for logistic regression)</span><br><span class="line">%           temp = theta; </span><br><span class="line">%           temp(1) = 0;   % because we don&apos;t add anything for j = 0  </span><br><span class="line">%           grad = grad + YOUR_CODE_HERE (using the temp variable)</span><br><span class="line">%</span><br><span class="line"></span><br><span class="line">J = 1 / m * sum(-y .* log(sigmoid(X * theta)) - (1 - y) .* log(1 - sigmoid(X * theta)))  + lambda/2/m*sum(theta(2:end) .^ 2);</span><br><span class="line">%J = 1/m * (-y&apos; * log(sigmoid(X*theta)) - (1 - y&apos;)* log(1-sigmoid(X*theta))) + lambda/2/m*sum(theta(2:end) .^ 2);</span><br><span class="line">grad(1, :) = 1/m * (X(:,1)&apos;* (sigmoid(X*theta) - y));</span><br><span class="line">grad(2:end, :) = 1/m * (X(:,2:end)&apos;* (sigmoid(X*theta) - y)) + lambda/m*theta(2:end, :);</span><br><span class="line"></span><br><span class="line">% =============================================================</span><br><span class="line"></span><br><span class="line">grad = grad(:);</span><br><span class="line"></span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="oneVsAll-m"><a href="#oneVsAll-m" class="headerlink" title=" oneVsAll.m "></a><strong> oneVsAll.m </strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">function [all_theta] = oneVsAll(X, y, num_labels, lambda)</span><br><span class="line">%ONEVSALL trains multiple logistic regression classifiers and returns all</span><br><span class="line">%the classifiers in a matrix all_theta, where the i-th row of all_theta </span><br><span class="line">%corresponds to the classifier for label i</span><br><span class="line">%   [all_theta] = ONEVSALL(X, y, num_labels, lambda) trains num_labels</span><br><span class="line">%   logistic regression classifiers and returns each of these classifiers</span><br><span class="line">%   in a matrix all_theta, where the i-th row of all_theta corresponds </span><br><span class="line">%   to the classifier for label i</span><br><span class="line"></span><br><span class="line">% Some useful variables</span><br><span class="line">m = size(X, 1);</span><br><span class="line">n = size(X, 2);</span><br><span class="line"></span><br><span class="line">% You need to return the following variables correctly </span><br><span class="line">all_theta = zeros(num_labels, n + 1);</span><br><span class="line"></span><br><span class="line">% Add ones to the X data matrix</span><br><span class="line">X = [ones(m, 1) X];</span><br><span class="line"></span><br><span class="line">% ====================== YOUR CODE HERE ======================</span><br><span class="line">% Instructions: You should complete the following code to train num_labels</span><br><span class="line">%               logistic regression classifiers with regularization</span><br><span class="line">%               parameter lambda. </span><br><span class="line">%</span><br><span class="line">% Hint: theta(:) will return a column vector.</span><br><span class="line">%</span><br><span class="line">% Hint: You can use y == c to obtain a vector of 1&apos;s and 0&apos;s that tell you</span><br><span class="line">%       whether the ground truth is true/false for this class.</span><br><span class="line">%</span><br><span class="line">% Note: For this assignment, we recommend using fmincg to optimize the cost</span><br><span class="line">%       function. It is okay to use a for-loop (for c = 1:num_labels) to</span><br><span class="line">%       loop over the different classes.</span><br><span class="line">%</span><br><span class="line">%       fmincg works similarly to fminunc, but is more efficient when we</span><br><span class="line">%       are dealing with large number of parameters.</span><br><span class="line">%</span><br><span class="line">% Example Code for fmincg:</span><br><span class="line">%</span><br><span class="line">%     % Set Initial theta</span><br><span class="line">%     initial_theta = zeros(n + 1, 1);</span><br><span class="line">%     </span><br><span class="line">%     % Set options for fminunc</span><br><span class="line">%     options = optimset(&apos;GradObj&apos;, &apos;on&apos;, &apos;MaxIter&apos;, 50);</span><br><span class="line">% </span><br><span class="line">%     % Run fmincg to obtain the optimal theta</span><br><span class="line">%     % This function will return theta and the cost </span><br><span class="line">%     [theta] = ...</span><br><span class="line">%         fmincg (@(t)(lrCostFunction(t, X, (y == c), lambda)), ...</span><br><span class="line">%                 initial_theta, options);</span><br><span class="line">%</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">initial_theta = zeros(n + 1, 1);</span><br><span class="line">options = optimset(&apos;GradObj&apos;, &apos;on&apos;, &apos;MaxIter&apos;, 50);</span><br><span class="line">for c = 1:num_labels</span><br><span class="line">    all_theta(c, :) = fmincg (@(t)(lrCostFunction(t, X, (y == c), lambda)), initial_theta, options);</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">% =========================================================================</span><br><span class="line"></span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="predictOneVsAll-m"><a href="#predictOneVsAll-m" class="headerlink" title=" predictOneVsAll.m "></a><strong> predictOneVsAll.m </strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">function p = predictOneVsAll(all_theta, X)</span><br><span class="line">%PREDICT Predict the label for a trained one-vs-all classifier. The labels </span><br><span class="line">%are in the range 1..K, where K = size(all_theta, 1). </span><br><span class="line">%  p = PREDICTONEVSALL(all_theta, X) will return a vector of predictions</span><br><span class="line">%  for each example in the matrix X. Note that X contains the examples in</span><br><span class="line">%  rows. all_theta is a matrix where the i-th row is a trained logistic</span><br><span class="line">%  regression theta vector for the i-th class. You should set p to a vector</span><br><span class="line">%  of values from 1..K (e.g., p = [1; 3; 1; 2] predicts classes 1, 3, 1, 2</span><br><span class="line">%  for 4 examples) </span><br><span class="line"></span><br><span class="line">m = size(X, 1);</span><br><span class="line">num_labels = size(all_theta, 1);</span><br><span class="line"></span><br><span class="line">% You need to return the following variables correctly </span><br><span class="line">p = zeros(size(X, 1), 1);</span><br><span class="line"></span><br><span class="line">% Add ones to the X data matrix</span><br><span class="line">X = [ones(m, 1) X];</span><br><span class="line"></span><br><span class="line">% ====================== YOUR CODE HERE ======================</span><br><span class="line">% Instructions: Complete the following code to make predictions using</span><br><span class="line">%               your learned logistic regression parameters (one-vs-all).</span><br><span class="line">%               You should set p to a vector of predictions (from 1 to</span><br><span class="line">%               num_labels).</span><br><span class="line">%</span><br><span class="line">% Hint: This code can be done all vectorized using the max function.</span><br><span class="line">%       In particular, the max function can also return the index of the </span><br><span class="line">%       max element, for more information see &apos;help max&apos;. If your examples </span><br><span class="line">%       are in rows, then, you can use max(A, [], 2) to obtain the max </span><br><span class="line">%       for each row.</span><br><span class="line">%       </span><br><span class="line"></span><br><span class="line">temp = all_theta * X&apos;;</span><br><span class="line">[maxx, pp] = max(temp);</span><br><span class="line">p = pp&apos;;</span><br><span class="line"></span><br><span class="line">% =========================================================================</span><br><span class="line"></span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="predict-m"><a href="#predict-m" class="headerlink" title=" predict.m "></a><strong> predict.m </strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">function p = predict(Theta1, Theta2, X)</span><br><span class="line">%PREDICT Predict the label of an input given a trained neural network</span><br><span class="line">%   p = PREDICT(Theta1, Theta2, X) outputs the predicted label of X given the</span><br><span class="line">%   trained weights of a neural network (Theta1, Theta2)</span><br><span class="line"></span><br><span class="line">% Useful values</span><br><span class="line">m = size(X, 1);</span><br><span class="line">num_labels = size(Theta2, 1);</span><br><span class="line"></span><br><span class="line">% You need to return the following variables correctly </span><br><span class="line">p = zeros(size(X, 1), 1);</span><br><span class="line"></span><br><span class="line">% ====================== YOUR CODE HERE ======================</span><br><span class="line">% Instructions: Complete the following code to make predictions using</span><br><span class="line">%               your learned neural network. You should set p to a </span><br><span class="line">%               vector containing labels between 1 to num_labels.</span><br><span class="line">%</span><br><span class="line">% Hint: The max function might come in useful. In particular, the max</span><br><span class="line">%       function can also return the index of the max element, for more</span><br><span class="line">%       information see &apos;help max&apos;. If your examples are in rows, then, you</span><br><span class="line">%       can use max(A, [], 2) to obtain the max for each row.</span><br><span class="line">%</span><br><span class="line"></span><br><span class="line">X = [ones(m, 1) X];</span><br><span class="line">XX = sigmoid(X*Theta1&apos;);</span><br><span class="line">pp = sigmoid([ones(size(XX, 1), 1) XX] * Theta2&apos;);</span><br><span class="line">[a, p] = max(pp, [], 2);</span><br><span class="line"></span><br><span class="line">% =========================================================================</span><br><span class="line"></span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="参考"><a href="#参考" class="headerlink" title=" 参考 "></a><strong> 参考 </strong></h3><p><a href="https://blog.csdn.net/jiangwennjust/article/details/6966172" target="_blank" rel="noopener">Octave基础</a></p>

  </section>

  
  
</article>


            <footer class="__share_wrapper">
    <span class="under0">
		<span class="text">关注我的微信公众号[<a href="/about/">李一二</a>]，即时看更多的文章</span>
	</span>
</footer>

<footer class="footer">
    <span class="footer__copyright">&copy; 2016-2021. | 由<a href="https://hexo.io/">Hexo</a>强力驱动 | 主题<a href="https://github.com/someus/huno">Huno</a> | <a href="https://beian.miit.gov.cn/">渝ICP备17002561号</a> | 不装弱了,我要做大佬</span>
</footer>

<script>
// 对特定页面的footer隐藏
// function find(str, aim, num) {
//    var resultIndex = str.indexOf(aim);
//    for(var i = 0; i < num - 1; i++){
//        resultIndex = str.indexOf(aim, resultIndex + 1);
//    }
//    return resultIndex;
//  }

// var __one = document.querySelector("#__one");
// var __tow = document.querySelector("#__tow");
// var __three = document.querySelector("#__three");
// var __threeIndex  = find(location.href, '/', 3);
// var __fourthIndex = find(location.href, '/', 4);
// var aimStr = '';

// if (__fourthIndex !== -1) {
//     aimStr = location.href.substring(__threeIndex + 1, __fourthIndex);
// } else if (__fourthIndex === -1) {
//     aimStr = location.href.substring(__threeIndex + 1);
// }

// switch (aimStr) {
//   case "":
//   case "#blog":
//   case "about":
//   case "archive":
//   case "categories":
//   case "tags":
//   case "page":
//     __one.style.display = "none";
//     __tow.style.display = "none";
//     __three.style.display = "none";
//     break;
// }
</script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-137711129-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-137711129-1');
</script>

        </div>
    </div>



    <!-- js files -->
    <script src="/js/jquery.min.js"></script>
    <script src="/js/main.js"></script>
    <script src="/js/scale.fix.js"></script>
    <script>

var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        success: function( xmlResponse ) {
            // get the contents from search data

            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "link" , this).attr("href")
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var str='<ul class=\"search-result-list\">';
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length <= 0) {
                    return;
                }

                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = true;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '' && data_content != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title < 0 && index_content < 0 ){
                                isMatch = false;
                            } else {
                                if (index_content < 0) {
                                    index_content = 0;
                                }
                                if (i == 0) {
                                    first_occur = index_content;
                                }
                            }
                        });
                    }
                    // show search results
                    if (isMatch) {

                        str += "<li><a href='"+ data_url  +"' class='search-result-title'>"+ data_title +"</a>";
                       console.log(data_url);
                        console.log("=====命中=====", data);


                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 100;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substr(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<em class=\"search-keyword\">"+keyword+"</em>");
                            });

                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                });
                str += "</ul>";
                $resultContent.innerHTML = str;
            });
        }
    });
};

var path = "/" + "search.xml";
searchFunc(path, 'local-search-input', 'local-search-result');
    </script>


    

    <script src="/js/awesome-toc.min.js"></script>
    <script>
        $(document).ready(function(){
            $.awesome_toc({
                overlay: true,
                contentId: "post-content",
            });
        });
    </script>


    
    
    <!--kill ie6 -->
<!--[if IE 6]>
  <script src="//letskillie6.googlecode.com/svn/trunk/2/zh_CN.js"></script>
<![endif]-->

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>
