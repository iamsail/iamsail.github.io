<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    

    <title>
      Tensorflow最佳实践之MNIST | Sail 
    </title>

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    
      <meta name="author" content="Sail">


    
    

<div id="site_search">
            <input type="text" id="local-search-input" name="q" results="0" placeholder="search my blog..." class="form-control">
            <div id="local-search-result"></div>
    </div>
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-1345496474366685",
        enable_page_level_ads: true
      });
    </script>


    <meta name="description" content="Preface 本文是用tensorflow实现全连接神经网络来解决MNIST问题的记录。 总共有三个文件,分别是mnist_inference.ipynb(定义了前向传播的过程以及神经网络中的参数),mnist_train.ipynb(定义了神经网络的训练过程),mnist_eval.ipynb(定义了测试过程)   mnist_inference 1234567891011121314151">
<meta name="keywords" content="TensorFlow,MNIST">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow最佳实践之MNIST | Sail">
<meta property="og:url" content="http://www.sail.name/2018/08/18/Best-practice-of-tensorflow-in-minst/index.html">
<meta property="og:site_name" content="Sail">
<meta property="og:description" content="Preface 本文是用tensorflow实现全连接神经网络来解决MNIST问题的记录。 总共有三个文件,分别是mnist_inference.ipynb(定义了前向传播的过程以及神经网络中的参数),mnist_train.ipynb(定义了神经网络的训练过程),mnist_eval.ipynb(定义了测试过程)   mnist_inference 1234567891011121314151">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2018-12-09T10:19:58.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tensorflow最佳实践之MNIST | Sail">
<meta name="twitter:description" content="Preface 本文是用tensorflow实现全连接神经网络来解决MNIST问题的记录。 总共有三个文件,分别是mnist_inference.ipynb(定义了前向传播的过程以及神经网络中的参数),mnist_train.ipynb(定义了神经网络的训练过程),mnist_eval.ipynb(定义了测试过程)   mnist_inference 1234567891011121314151">
    
    
    
      <link rel="icon" type="image/x-icon" href="/favicon.png">
    
    <link rel="stylesheet" href="/css/uno.css">
    <link rel="stylesheet" href="/css/highlight.css">
    <link rel="stylesheet" href="/css/archive.css">
    <link rel="stylesheet" href="/css/china-social-icon.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
<body>

    <!-- hexo-inject:begin --><!-- hexo-inject:end --><span class="mobile btn-mobile-menu">
        <i class="icon icon-list btn-mobile-menu__icon"></i>
        <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>

    </span>

    

<header class="panel-cover panel-cover--collapsed">


  <div class="panel-main">

  
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        

        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage">Sail</a></h1>
        <hr class="panel-cover__divider">

        
        <p class="panel-cover__description">
          手在键盘敲很轻
        </p>
        <hr class="panel-cover__divider panel-cover__divider--secondary">
        

        <div class="navigation-wrapper">

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">

              
                
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">首页</a></li>

              
                
                <li class="navigation__item"><a href="/about" title="" class="">关于</a></li>

              
                
                <li class="navigation__item"><a href="/archive" title="" class="">归档</a></li>

              
               <li class="navigation__item">
                    <a href="http://www.sail.name/Resource/" title="个人资源分享">Resource</a></li>

            </ul>
          </nav>
          <!-- ----------------------------
To add a new social icon simply duplicate one of the list items from below
and change the class in the <i> tag to match the desired social network
and then add your link to the <a>. Here is a full list of social network
classes that you can use:

    icon-social-500px
    icon-social-behance
    icon-social-delicious
    icon-social-designer-news
    icon-social-deviant-art
    icon-social-digg
    icon-social-dribbble
    icon-social-facebook
    icon-social-flickr
    icon-social-forrst
    icon-social-foursquare
    icon-social-github
    icon-social-google-plus
    icon-social-hi5
    icon-social-instagram
    icon-social-lastfm
    icon-social-linkedin
    icon-social-medium
    icon-social-myspace
    icon-social-path
    icon-social-pinterest
    icon-social-rdio
    icon-social-reddit
    icon-social-skype
    icon-social-spotify
    icon-social-stack-overflow
    icon-social-steam
    icon-social-stumbleupon
    icon-social-treehouse
    icon-social-tumblr
    icon-social-twitter
    icon-social-vimeo
    icon-social-xbox
    icon-social-yelp
    icon-social-youtube
    icon-social-zerply
    icon-mail

-------------------------------->

<!-- add social info here -->



<nav class="cover-navigation navigation--social">
  <ul class="navigation">
    
      <!-- Github -->
      <li class="navigation__item">
        <a href="https://github.com/iamsail" title="Huno on GitHub">
          <i class="icon icon-social-github"></i>
          <span class="label">GitHub</span>
        </a>
      </li>
    

    <!-- China social icon -->
    <!--
    
      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-douban'></i>
          <span class="label">Douban</span>
        </a>
      </li>

      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-weibo'></i>
          <span class="label">Weibo</span>
        </a>
      </li>

    -->



  </ul>
</nav>


        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner entry">
            

<article class="post-container post-container--single">

  <header class="post-header">
    
    <h1 class="post-title">Tensorflow最佳实践之MNIST</h1>

    

    <div class="post-meta">
      <time datetime="2018-08-18" class="post-meta__date date">2018-08-18</time> 

      <span class="post-meta__tags tags">

          
            <font class="categories">
            &#8226; 分类:
            <a class="categories-link" href="/categories/深度学习/">深度学习</a>
            </font>
          

          
             &#8226; 标签:
            <font class="tags">
              <a class="tags-link" href="/tags/MNIST/">MNIST</a>, <a class="tags-link" href="/tags/TensorFlow/">TensorFlow</a>
            </font>
          

      </span>
    </div>
    
    

  </header>

  <section id="post-content" class="article-content post">
    <h3 id="Preface"><a href="#Preface" class="headerlink" title=" Preface "></a><strong> Preface </strong></h3><p>本文是用tensorflow实现全连接神经网络来解决MNIST问题的记录。</p>
<p>总共有三个文件,分别是<code>mnist_inference.ipynb</code>(定义了前向传播的过程以及神经网络中的参数),<code>mnist_train.ipynb</code>(定义了神经网络的训练过程),<code>mnist_eval.ipynb</code>(定义了测试过程)</p>
<hr>
<h4 id="mnist-inference"><a href="#mnist-inference" class="headerlink" title=" mnist_inference "></a><strong> mnist_inference </strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义神经网络结构相关的参数</span></span><br><span class="line">INPUT_NODE = <span class="number">784</span></span><br><span class="line">OUTPUT_NODE = <span class="number">10</span></span><br><span class="line">LAYER1_NODE = <span class="number">500</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过get_variable函数来获取变量。在训练神经网络时,会创建这些变量;</span></span><br><span class="line"><span class="comment"># 在通过测试时会通过保存的模型加载这些变量的取值。而且更加方便的是,因为可以在</span></span><br><span class="line"><span class="comment"># 变量加载时将滑动平均变量重命名,所以可以直接通过同样的名字在训练时使用变量自身,而</span></span><br><span class="line"><span class="comment"># 在测试时使用变量的滑动平均值。在这个函数中也会将变量的正则化损失加入损失集合</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_weight_variable</span><span class="params">(shape, regularizer)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">''</span>, reuse=tf.AUTO_REUSE):</span><br><span class="line">        weights = tf.get_variable(</span><br><span class="line">        <span class="string">"weights"</span>, shape,</span><br><span class="line">        initializer = tf.truncated_normal_initializer(stddev = <span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 当给出了正则化生成函数时,将当前变量的正则化损失加入名字为losses的集合。</span></span><br><span class="line">        <span class="comment"># 在这里使用了add_to_collection函数将一个张量加入一个集合,而这个集合的名称为losses,</span></span><br><span class="line">        <span class="comment"># 这是自定义的集合, 不在tensorflow自动管理的集合列表中</span></span><br><span class="line">        <span class="keyword">if</span> regularizer != <span class="keyword">None</span>:</span><br><span class="line">            tf.add_to_collection(<span class="string">'losses'</span>, regularizer(weights))</span><br><span class="line">        <span class="keyword">return</span> weights</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line"><span class="comment"># 定义神经网络的前向传播过程</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference</span><span class="params">(input_tensor, regularizer)</span>:</span></span><br><span class="line">    <span class="comment"># 声明第一层神经网络的变量并完成前向传播过程</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'layer1'</span>, reuse=tf.AUTO_REUSE):</span><br><span class="line">        weights = get_weight_variable(</span><br><span class="line">            [INPUT_NODE, LAYER1_NODE], regularizer)</span><br><span class="line">        </span><br><span class="line">        biases = tf.get_variable(</span><br><span class="line">            <span class="string">'biases'</span>, [LAYER1_NODE],</span><br><span class="line">            initializer = tf.constant_initializer(<span class="number">0.0</span>))</span><br><span class="line">        </span><br><span class="line">        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights) + biases)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 声明第二层神经网络的变量并完成前向传播过程    </span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'layer2'</span>, reuse=tf.AUTO_REUSE):</span><br><span class="line">        weights = get_weight_variable(</span><br><span class="line">            [LAYER1_NODE, OUTPUT_NODE], regularizer)</span><br><span class="line">        </span><br><span class="line">        biases = tf.get_variable(</span><br><span class="line">            <span class="string">"biases"</span>, [OUTPUT_NODE],</span><br><span class="line">            initializer = tf.constant_initializer(<span class="number">0.0</span>))</span><br><span class="line">        </span><br><span class="line">        layer2 = tf.matmul(layer1, weights) + biases</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 返回最终的前向传播过程</span></span><br><span class="line">    <span class="keyword">return</span> layer2</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="mnist-train"><a href="#mnist-train" class="headerlink" title=" mnist_train "></a><strong> mnist_train </strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> Ipynb_importer</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span>  input_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载mnist_inference中定义的常量和前向传播函数</span></span><br><span class="line"><span class="keyword">import</span> mnist_inference</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置神经网络的参数</span></span><br><span class="line">BATCH_SIZE = <span class="number">100</span></span><br><span class="line">LEARNING_RATE_BASE = <span class="number">0.8</span></span><br><span class="line">LEARNING_RATE_DECAY = <span class="number">0.99</span></span><br><span class="line">REGULARAZTION_RATE = <span class="number">0.0001</span></span><br><span class="line">TRAINING_STEPS = <span class="number">30000</span></span><br><span class="line">MOVING_AVERAGE_DECAY = <span class="number">0.99</span></span><br><span class="line"><span class="comment"># 模型保存的路径和文件名</span></span><br><span class="line">MODEL_SAVE_PATH = <span class="string">"/home/sail/hacker/dl/model"</span></span><br><span class="line">MODEL_NAME = <span class="string">"sail.ckpt"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(mnist)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">''</span>, reuse=tf.AUTO_REUSE):</span><br><span class="line">        <span class="comment"># 定义输入输出placeholder</span></span><br><span class="line">        x = tf.placeholder(</span><br><span class="line">            tf.float32, [<span class="keyword">None</span>, mnist_inference.INPUT_NODE], name=<span class="string">"x-input"</span>)</span><br><span class="line">        y_ = tf.placeholder(</span><br><span class="line">            tf.float32, [<span class="keyword">None</span>, mnist_inference.OUTPUT_NODE], name=<span class="string">"y-input"</span>)</span><br><span class="line"></span><br><span class="line">        regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)</span><br><span class="line">        <span class="comment">#　直接使用mnist_inference中定义的前向传播过程</span></span><br><span class="line">        y = mnist_inference.inference(x, regularizer)</span><br><span class="line">        global_step = tf.Variable(<span class="number">0</span>, trainable=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">        variable_averages = tf.train.ExponentialMovingAverage(</span><br><span class="line">            MOVING_AVERAGE_DECAY, global_step)</span><br><span class="line"></span><br><span class="line">        variable_averages_op = variable_averages.apply(</span><br><span class="line">            tf.trainable_variables())</span><br><span class="line"></span><br><span class="line">        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(</span><br><span class="line">            labels = tf.argmax(y_, <span class="number">1</span>), logits =y )</span><br><span class="line">    <span class="comment">#     cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(</span></span><br><span class="line">    <span class="comment">#         labels = y, logits = tf.argmax(y_, 1))</span></span><br><span class="line"></span><br><span class="line">        cross_entropy_mean = tf.reduce_mean(cross_entropy)</span><br><span class="line">        loss = cross_entropy_mean + tf.add_n(tf.get_collection(<span class="string">'losses'</span>))</span><br><span class="line">        learning_rate = tf.train.exponential_decay(</span><br><span class="line">            LEARNING_RATE_BASE,</span><br><span class="line">            global_step,</span><br><span class="line">            mnist.train.num_examples / BATCH_SIZE,</span><br><span class="line">            LEARNING_RATE_DECAY)</span><br><span class="line"></span><br><span class="line">        train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.control_dependencies([train_step, variable_averages_op]):</span><br><span class="line">            train_op = tf.no_op(name=<span class="string">'train'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 初始化TensorFlow持久类</span></span><br><span class="line">        saver = tf.train.Saver()</span><br><span class="line">        <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">            tf.initialize_all_variables().run()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 在训练过程中不再测试模型在验证数据上的表现,验证和测试的过程将会有一个独立的程序来完成</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(TRAINING_STEPS):</span><br><span class="line">                xs, ys = mnist.train.next_batch(BATCH_SIZE)</span><br><span class="line">                _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict=&#123;x: xs, y_:ys&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="comment">#　每1000轮保存一次模型</span></span><br><span class="line">                <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">                    <span class="comment"># 输出当前的训练情况。这里只输出了模型在当前训练batch上的损失函数大小。</span></span><br><span class="line">                    <span class="comment"># 通过损失函数的大小可以大概了解训练的情况。在验证数据集上的正确率信息会有一个单独的程序来生成</span></span><br><span class="line">                    print(<span class="string">"after %d training step(s), loss on training batch is %g "</span> % (step, loss_value))</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 保存当前的模型。注意这里给出了global_step参数,　这样可以让每个被保存模型的文件名末尾加上训练轮数,比如</span></span><br><span class="line">                    <span class="comment"># "sail.ckpt-1000"表示训练1000轮之后得到的模型</span></span><br><span class="line">                    saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)    </span><br><span class="line"></span><br><span class="line">                </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(argv=None)</span>:</span></span><br><span class="line">    mnist = input_data.read_data_sets(<span class="string">"/home/sail/hacker/dl/tensorflow/book-one/MNISTData"</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line">    train(mnist)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    tf.app.run()</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="mnist-eval"><a href="#mnist-eval" class="headerlink" title=" mnist_eval "></a><strong> mnist_eval </strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> Ipynb_importer</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载mnist_inference 和 mnist_train.py中定义的常量和函数</span></span><br><span class="line"><span class="keyword">import</span> mnist_inference</span><br><span class="line"><span class="keyword">import</span> mnist_train</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每10秒加载一次模型，并在测试数据集上测试最新的模型正确率</span></span><br><span class="line">EVAL_INTERVAL_SECS = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(mnist)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.Graph().as_default() <span class="keyword">as</span> g:</span><br><span class="line">        <span class="comment"># 定义输入输出的格式</span></span><br><span class="line">        x = tf.placeholder(</span><br><span class="line">            tf.float32, [<span class="keyword">None</span>, mnist_inference.INPUT_NODE], name=<span class="string">"x-input"</span>)</span><br><span class="line">        y_ = tf.placeholder(</span><br><span class="line">            tf.float32, [<span class="keyword">None</span>, mnist_inference.OUTPUT_NODE], name=<span class="string">"y-input"</span>)</span><br><span class="line">        </span><br><span class="line">        validate_feed = &#123;x: mnist.validation.images,</span><br><span class="line">                        y_: mnist.validation.labels&#125;</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 直接通过调用封装好的函数来计算前向传播结果。因为测试时不关注正则化损失的值</span></span><br><span class="line">        <span class="comment"># 所以这里用于计算正则化损失的函数被设置为None</span></span><br><span class="line">        y = mnist_inference.inference(x, <span class="keyword">None</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 使用前向传播结果计算正确率。如果需要对未知的样例进行分类,那么使用tf.argmax(y, 1)就可以得到输入样例的预测类别了</span></span><br><span class="line">        correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line">        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 通过变量重命名的方式来加载模型,这样在前向传播的过程中就不需要调用求滑动平均的函数来获取平均值了。这样就可以完全</span></span><br><span class="line">        <span class="comment"># 共用mnist_inference中定义的前向传播过程</span></span><br><span class="line">        variable_averages = tf.train.ExponentialMovingAverage(</span><br><span class="line">            mnist_train.MOVING_AVERAGE_DECAY)</span><br><span class="line">        variables_to_restore = variable_averages.variables_to_restore()</span><br><span class="line">        saver = tf.train.Saver(variables_to_restore)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#每隔EVAL_INTERVAL_SECS秒调用一次计算正确率的过程以检测训练过程中正确率的变化</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">            <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">                <span class="comment"># tf.train.get_checkpoint_state函数通过checkpoint文件自动找到目录中最新模型的文件名</span></span><br><span class="line">                ckpt = tf.train.get_checkpoint_state(</span><br><span class="line">                    mnist_train.MODEL_SAVE_PATH)</span><br><span class="line">                <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line">                    <span class="comment"># 加载模型</span></span><br><span class="line">                    saver.restore(sess, ckpt.model_checkpoint_path)</span><br><span class="line">                    <span class="comment"># 通过文件名得到模型保存时迭代的轮数</span></span><br><span class="line">                    global_step = ckpt.model_checkpoint_path.split(<span class="string">'/'</span>)[<span class="number">-1</span>].split(<span class="string">'-'</span>)[<span class="number">-1</span>]</span><br><span class="line">                    accuracy_score = sess.run(accuracy, feed_dict=validate_feed)</span><br><span class="line">                    print(<span class="string">"after %s training step(s), validation accuracy = %g "</span> % (global_step, accuracy_score))</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    print(<span class="string">'No checkpoint file found'</span>)</span><br><span class="line">                    <span class="keyword">return</span></span><br><span class="line">                time.sleep(EVAL_INTERVAL_SECS)</span><br><span class="line">                </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(argv=None)</span>:</span></span><br><span class="line">    mnist = input_data.read_data_sets(<span class="string">"/home/sail/hacker/dl/tensorflow/book-one/MNISTData"</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line">    evaluate(mnist)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    tf.app.run()</span><br></pre></td></tr></table></figure>
  </section>

  
  
</article>


            <footer class="footer">
    <span class="footer__copyright">&copy; 2016-2021. | 由<a href="https://hexo.io/">Hexo</a>强力驱动 | 主题<a href="https://github.com/someus/huno">Huno</a> | 渝ICP备17002561号 | 不装弱了,我要做大佬</span>
</footer>

<script>
// 对特定页面的footer隐藏
// function find(str, aim, num) {
//    var resultIndex = str.indexOf(aim);
//    for(var i = 0; i < num - 1; i++){
//        resultIndex = str.indexOf(aim, resultIndex + 1);
//    }
//    return resultIndex;
//  }

// var __one = document.querySelector("#__one");
// var __tow = document.querySelector("#__tow");
// var __three = document.querySelector("#__three");
// var __threeIndex  = find(location.href, '/', 3);
// var __fourthIndex = find(location.href, '/', 4);
// var aimStr = '';

// if (__fourthIndex !== -1) {
//     aimStr = location.href.substring(__threeIndex + 1, __fourthIndex);
// } else if (__fourthIndex === -1) {
//     aimStr = location.href.substring(__threeIndex + 1);
// }

// switch (aimStr) {
//   case "":
//   case "#blog":
//   case "about":
//   case "archive":
//   case "categories":
//   case "tags":
//   case "page":
//     __one.style.display = "none";
//     __tow.style.display = "none";
//     __three.style.display = "none";
//     break;
// }
</script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-137711129-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-137711129-1');
</script>

        </div>
    </div>



    <!-- js files -->
    <script src="/js/jquery.min.js"></script>
    <script src="/js/main.js"></script>
    <script src="/js/scale.fix.js"></script>
    <script>

var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        success: function( xmlResponse ) {
            // get the contents from search data

            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "link" , this).attr("href")
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var str='<ul class=\"search-result-list\">';
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length <= 0) {
                    return;
                }

                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = true;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '' && data_content != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title < 0 && index_content < 0 ){
                                isMatch = false;
                            } else {
                                if (index_content < 0) {
                                    index_content = 0;
                                }
                                if (i == 0) {
                                    first_occur = index_content;
                                }
                            }
                        });
                    }
                    // show search results
                    if (isMatch) {

                        str += "<li><a href='"+ data_url  +"' class='search-result-title'>"+ data_title +"</a>";
                       console.log(data_url);
                        console.log("=====命中=====", data);


                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 100;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substr(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<em class=\"search-keyword\">"+keyword+"</em>");
                            });

                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                });
                str += "</ul>";
                $resultContent.innerHTML = str;
            });
        }
    });
};

var path = "/" + "search.xml";
searchFunc(path, 'local-search-input', 'local-search-result');
    </script>


    

    <script src="/js/awesome-toc.min.js"></script>
    <script>
        $(document).ready(function(){
            $.awesome_toc({
                overlay: true,
                contentId: "post-content",
            });
        });
    </script>


    
    
    <!--kill ie6 -->
<!--[if IE 6]>
  <script src="//letskillie6.googlecode.com/svn/trunk/2/zh_CN.js"></script>
<![endif]-->

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>
